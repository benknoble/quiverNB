{
  "title": "31 August // Lecture 4",
  "cells": [
    {
      "type": "latex",
      "language": "latex",
      "data": "Matrix Multiplication\n(Because eventually we want to solve $Ax = b$)\n\nDon't forget about adult chickens\n\n(1) Matrix times a vector\n\n$m \\times n$ matrix $A$ times $n$ vector $x$ is an $m$ vector $v$ with entries $v_i = \\sum\\limits_1^n {a_{ij} x_j}$\n\nLike a dot product\n\n(2) Matrix times a Matrix\n\n$$\\matrixstart A \\matrixend \\matrixstart v_1 & v_2 & v_3 \\matrixend = \\matrixstart Av_1 & Av_2 & Av_3 \\matrixend$$\nfor $v_i$ is a column vector, $A$ is a matrix, and $Av_i$ denotes the column vector obtained by multiplication\n\n(3) $Ax = b$\n\nClearly, $x = A^{-1}b$, but finding $A^{-1}$ is harder. Remember matrix multiplication is not commutative.\n\nFind $B$ such that $BA = I$; then $B = A^{-1}$\n\nThe $2 \\times 2$ case is trivial\n\nInconsistent (not always solvable) $\\iff$ $rref(A)$ has a row of $0$s\n\n(4) Linear Dependence\n\n$u_1, u_2, \\dots, u_n$ are linearly dependent if one can be expressed as a linear combination of the others\nThat is, if $x_1u_1 + x_2u_2 + \\dots + x_nu_n = 0$ for some $x_1, x_2, \\dots, x_n \\neq 0$\n\nConstruct $A = \\matrixstart u_1 & u_2 & \\dots & u_n \\matrixend$, then examine $Ax = 0$\nIf $rref(A)$ is the standard $I$ identity matrix, they are linearly independent\nOtherwise, they are linearly dependent.\nYou can use the solution $x$ to identify the linear dependence and express one vector in terms of the others.\nSEE WKSHT $4$"
    }
  ]
}