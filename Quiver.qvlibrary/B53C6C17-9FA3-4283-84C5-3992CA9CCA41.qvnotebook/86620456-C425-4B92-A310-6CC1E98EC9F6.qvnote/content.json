{
  "title": "1 March // Lecture 14",
  "cells": [
    {
      "type": "markdown",
      "data": "Exam coming up (no scantron; simply pencil)--cf. [Exam Info](http://www.cs.unc.edu/~stotts/COMP410-s17/examinfo.html) on website\n\nPoll Everywhere\n\n> Q: After inserting 'lambda', there is an imbalance. Click on the node in this tree that has an imbalance according to the AVL tree condition\n> A: See image; 'gamma' because right subtree has height 2; left has height -1. Additionally, there was an imbalance at 'gamma' *before* the insertion of 'lambda'!\n\n> Q: In an AVL tree with $n$ nodes, each access operation (insert, remove, contains, findMin, etc.) has worst case time complexity of $O(\\log n)$.\n> A: True. Because of the balance, we never experience the $O(n)$ degenerate case.\n\n> Q: Consider an AVL tree of $n$ nodes. Consider the paths from root to leaves. The longest such path and the shortest such path will always differ by no more than 1.\n> A: False: apparently, there is an image of such a tree that breaks this condition\n\n#AVL Rotations (cont.)\nSeveral cases (LL = RR are single, RL = LR are double)\ncommon mistake: forgetting to update parent pointers\n\nEasy way to manage rotations: do it via the patterns presented. Grab pointers to subtrees $A,B,C,D$ and the nodes to rotate $P,Q,R$ and rewrite the connections. Constant work. Don't forget to update parent pointers! (slightly different for a single rotation, but similary)\n\n##Signatures (ADT)\nSame as BST! The difference is simply the implmentation of `insert` and `remove`\nAs we've seen, everything is $O(\\log n)$ in the worst case and avg\n\nWe have to modify our `Node` class to keep track of it's height, but that's relatively simple. I think it is also easier to give them parent pointers, but this is not strictly necessary\n\n#Splay Trees\nSlightly easier to write, but harder to guarantee. We get to talk about amortized analysis.\nADT is that of BST\n\nThere is no balance property to maintain!\nInstead we splay the tree at various times\nMost of the time this works, but not every time. However, the good will balance out the bad and give overall acceptable behavior\nWe do this splay practically any time the tree is touched\nBuilt on concept of *locality*: when you access something, you typically need to access it again\nEnd result of splay, the node touched at the root or near it, so even if it took a lot of time to get there the first time, it only takes a couple of operations the next several times\nEverything works out over time (hence amortized analysis)\n\nAfter `insert` or `search`, we push the node upward to the root by a series of AVL rotations\n\n##Cases of Rotation for a Node $X$ that is not the root\n1. (zig) $X$ has a parent $P$, but no grandparent\n - Single rotation becase $X$ is one level down from the root\n - Same as AVL rotation\n2. (zig-zig) (RR) $X$ is the right child of parent $P$, and $P$ is right child of grandparent $G$\n - Has symmetry to LL, zag-zag\n - Two rotations up the tree, basically two single rotations. First at $P$, then at $X$ \n3. (zig-zag) (RL) $X$ is the right child of $P$ which is the left child of $G$\n - Has symmetry to LR, zag-zig\n - Two rotations, rotate $X$ twice\n\nUse the patterns! See ppt.\n\nWhen do we splay?\n- insert: splay the new node to the root (after the BST-style insert), so each insert gives a new root\n- contains: if node is found, splay it to the root; otherwise, splay the last node found with a null subtree that causes it not to be found (splay it to the root)\n- findMin/Max: splay the found node to the root\n- remove: splay the parent of removed node to the root after BST-style remove\n- remove (alternate): splay the node to-be-removed to the root, remove the root, and join the two disconnected trees\n(We will be using the alternate approach)\n\n##Signatures\nSame as BST, only the operations that touch the tree cause a `splay`\n\n##Analysis\nWe don't have a guarantee of short fluffy paths; it is possible for them to get long, but deep access into it tend to shorten the tree somewhat. Overall, it is very possible to get $O(n)$ complexity on a *single* operation. However, over a long enough sequence of $k$ operations, we get $O(k\\log n)$ complexity\n\nThus, the worst case on operations is *amortized* $O(\\log n)$\n\nHow long is long enough? For now, on the order of $k \\ge \\sim20$"
    }
  ]
}