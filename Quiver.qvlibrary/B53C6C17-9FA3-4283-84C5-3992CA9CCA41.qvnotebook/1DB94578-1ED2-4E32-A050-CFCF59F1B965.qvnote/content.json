{
  "title": "27 March // Lecture 17",
  "cells": [
    {
      "type": "markdown",
      "data": "Watched footage of UNC beating Kentucky (related, because, uh, brackets=trees?)\nWorked out that you're trying to beat odds of $2^{63}$\n\nFinishing hashing, starting graphs. Graphs will be next assignment\n\nNo PollEv.\n\n#Hashing (cont.)\n\n###Collision Resolution\n- Hashing into lists (buckets, containing): each array slot contains a list rather than a single element\n- Linear probing: each slot contains one element, but there is a plan to pick the next slot to try in case of a collision\n\n**Hash to Lists**\nTable entry is null or a list of cells\nEach cell contains a data object (key-value pair)\nIf we hash to a key containing cells, we add to the list\nTo check if the key is there, we go to the slot it hashes to and scan the list ($O(n)$ with length of list) to see if it's there\n\nEasy to do, and it's how Java does it. But there's a twist, because we don't want the list at each cell to get too long and remove our $O(1)$ efficiency. We want a way to keep the lists short.\n\nWe could hang BST/AVL trees off the array slots, but it's difficult to do and doesn't get down to $O(1)$.\n\nSo we simply make the table bigger (double the size) to avoid there being many collisions. This keeps the list short.\n\n**Linear Probing**\nTable entry is null or single cell\nEach cell contains data object (key-value pair)\nOn a collision, we try other slots \"near by\"\nThis is a systematic, repeatable procedure\n\nBasically, if we hash to slot $h$ and `table[h]` is full, we try $h+1, h+2, h+3, \\dots$ until we find an open slot\n\nProblems? We have clumps or clusters of heavily used spots due to a set of collisions\n\nSolution: large table size (and, as always, a better--and possibly custom--hash function)\nSolution 2: probe more randomly (can't be truly random or we'll never find anything)\n\nGeneral formula: hash to slot $h$ and add some function $f(i)$ to the key. Define $f(0) = 0$.\nAt each attempt, the $f(i)$ determines how far away we look to find the slot.\nA key $k$ defines a sequence of hash values $h_0, h_1, h_2, h_2, \\dots$ defined by $h_i = h(k) + f(i), f(0) = 0, f(i) = i$\n\nChanging $f(i)$ allows you to skip by an arbitrary number, or even quadratically probe\n\n(this is of course all `% table.length`)\n\nSolution 3: Double hashing\nProbe by adding a secondary hash value. Effectively, $f(i) = h_2(k) \\times i$.\nRequires $h_2(k) \\neq 0$\n\n**Load $\\lambda$**\nOptimal value varies\n[assume $h$ is a well-distributed hash function]\nFor chaining, $\\lambda$ can get bigger than $1$. Not possible for probing.\n$\\lambda$ for probing should be $\\frac 1 2$\n$\\lambda$ for chaining should $1$\n\nJava uses chaining for `HashMap`, uses default load of $.75$, but it is overridable\n\nIgnored the `remove` function so far...\nAdditionally, doubling the table size means our hash function is wrong\nWe have to rehash everything ($O(n)$), but incurred relatively infrequently and typically when the table is small\n\nFor chaining, remove is pretty simple: hash, find, delete. With short lists, we get about $O(1)$\n\nFor probing, we can't simply empty the cell because it was cause a gap in the probe chain. We have to shift all the elements in the chain *down* by the chaining factor... problem is, we don't have a record for this. We can't really remove it. We can leave it in the table and mark it 'removed', allowing us to ignore it but use it as stepping stone. We can also overwrite these items when we insert new items. This is lazy deletion.\n\n#Graph Theory\n##Definitions\nA *graph* is *NOT* a bar chart. It's a mathematical entity.\nIt represents items and their relationships.\n$G = (V,E)$ where $V$ is a set of vertices (nodes), $E$ is a set of edges (arcs)\n- directed graph: $E$ is a set of ordered pairs (there is a an edge from $a$ to $b$ in $(a,b)$)\n- undirected graph: $E$ is a set of sets (there is an edge between $a$ and $b$ in ${a,b}$)\n\n**adjacent**\n$b$ is adjacent to $a$ iff $(a,b) \\in E$\n\n**di-graph (directed graph)**\nedges are directed with arrows\n\nSee ppt for examples of the $V,E$ sets\n\nFor an undirected graph, $b.adj.a \\implies a.adj.b$\n\n**weighted edges**\nEdges have a weight or cost associated with them\n(unweighted graphs can be thought of as having weight 1 on each edge)\n\n**path**\nis sequence of vertices $n_1,n_2,\\dots,n_k$ where $(n_i,n_{i+1}) \\in E$\n**length**\n$k-1$\nEvery vertex has a path of length $0$ to itself; however, if there is an edge $(b,b) \\in E$ then the path has length $1$!\n\n**simple path**\nvertices are distinct (not repeated) but the beginning and end are allowed to be the same\n\n**cycle (in digraph)**\npaths of length greater than 1 that ends on start\n**cycle (in undirected graph)**\nrequire the edges to be distinct\n\n**DAG (directed acyclic graph)**\nspecial form used for many problems\ne.g. linked lists, trees\n\n##Graph Algorithms\n- Determine if a cycle exists?\nna√Øve approach (check all possible paths) usually inefficient: combinatorial explosion\n\nto be continued..."
    }
  ]
}