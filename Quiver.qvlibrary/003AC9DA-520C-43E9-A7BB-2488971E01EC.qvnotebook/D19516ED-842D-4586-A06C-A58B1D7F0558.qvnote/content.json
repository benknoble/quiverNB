{
  "title": "Takehome Midterm 2",
  "cells": [
    {
      "type": "latex",
      "language": "latex",
      "data": "2(a). Problem summary: We may choose to exercise our stock option at any time in the window of the next $n$ days, buying at price $s$ and selling at the price $S_i$ (a random variable indicating the price on day $i$, $1 \\le i \\le n$) for a profit $S_i - s$. We wish to maximize the profit.\n\nIf we knew the stock prices in advance (all the $S_{1 \\dots n}$ were fixed), the problem would be trivial: pick the day with the highest value of $S_i$.\n\nDefine $\\pi(i)$ to be the profit gained by selling on day $i$; the function is random, because it depends on the random variable $S_i$:\n\n\\[\n\\pi(i) = \\begin{cases}\n    S_i - s, & S_i \\gt s \\\\\n    0, & S_i \\le s\n\\end{cases}\n\\]\n\nThen we can define the maximum profit in a window to be $P$ with inputs $s, e \\in \\{1 \\dots n\\}$ the start and end days, and output maximum profit in the given window.\n\nWe note that if the window is empty, then our profit is zero. Further, on a given day, we have the choice to sell now for profit $\\pi$, or wait til the next day and re-evaluate. We want the maximum of these two values.\n\n\\[\nP(s, e) = \\begin{cases}\n    0, & s \\gt e \\\\\n    \\max\\big(\\pi(s), P(s + 1, e)\\big), & \\text{else}\n\\end{cases}\n\\]\n\nThen we seek $P(1,n)$.\n\nUnfortunately, we don't have the values of all the $S_i$; we could use expected values $E[S_i] - s$ if we had supplementary information about the stock fluctuation. Further, note that this recurrence effectively expands to $\\max_{i \\in \\{1 \\dots n\\}}\\pi(i)$, whcih is solved as mentioned above by the $j$ such that $S_j = \\max S_i$.\n\nhttps://web.stanford.edu/group/msande-history/wikiupload/6/6e/Veinott_Dynamic_Programming_course_notes.pdf contains an interesting analysis of a similar problem using expected values.\n\n2(b). In the new definition of the problem, each $S_i$ comes from the same distribution, and any day might be the optimal day.\n\nThe Secretary problem is a generalization of this problem, where an interviewer will interview applicants, and must immediately make a decision to reject or accept the applicant. Rejecting the applicant is here analogous to not exercising our option; we can never recall the applicant, nor can we return to a day past. If we exercise our option, hiring the applicant, then we cannot do so in the future, even should an applicant or stock price be more attractive.\n\nThe Secretary problem has the interesting result that the optimal strategy, that is, the strategy that maximizes the probability of hiring the best applicant, is to reject the first $r$ applicants, and then select the first applicant better than all those rejected.\n\nThis strategy has probability of success $\\lim_{n \\to \\infty}\\Pr = \\frac{1}{e}$; the cutoff $r$ tends to $\\frac{n}{e}$ for large $n$. (Here $e$ is the base of the natural logarithm $\\ln$ such that $\\ln(e) = 1$.)\n\nApplying it to our problem of stock \"call\" options, we find that for large windows of $n$ days, our best strategy is to wait $\\frac{n}{e}$ days and then sell at the first day with price larger than all those preceding.\n\nNote that this strategy is only optimal when the \"best applicant\" (read: maximum stock value) is equally likely to be any one of the $n$-to-come. Stock values in real life do not behave quite that way, as the distribution is affected day-to-day.\n\n3. Presents a problem equivalent to the (infamous) knapsack problem. In fact, it is a variant of the knapsack problem known as the 0/1 KP.\n\nHere I will denote the $n$ items $i = (b_i, w_i)$, a tuple of benefit and weight. Further, I will generally assume $\\forall i : w_i \\le W$; otherwise, a single $\\Theta(n)$ pass suffices to eliminate the items impossible to carry with us.\n\n(a). If a greedy algorithm takes the best benefit, it is easy to devise a set of inputs such that the greedy solution is not optimal:\n$W = 5$\nItems:\n$\\{\n(5,5),\n(2,1)\\times5\n\\}$, that is, 5 of the $(2,1)$ item (they appear identical, but could in fact be disparate items valuated similarly).\nThe greedy algorithm takes the first item for a total benefit of $5$, but the correct approach takes all the lighter items for a total benefit of $10 \\gt 5$. \n\nIf the greedy algorithm optimizes for ratio, then give:\n$W = 7$\nItems:\n$\\{\n(7,3)\\times2,\n(13,5)\n\\}$\nThe ratios compare as follows: $\\frac{13}{5} \\gt \\frac{7}{3}$, but it is optimal to take the lighter items for a total benefit of $14 \\gt 13$.\n\n(b). Let $v(i, w)$ be the most benefit (value) our cyclist can get in under a weight $w$ using at most the first $i$ items. Then we seek $v(n,W)$.\n\nWe note that $\\forall w : v(0,w)$ is trivially $0$, since we cannot benefit if we take no items.\n\nFor $w \\gt 0$, we have a choice to add the item with weight $w_i \\le w$ and benefit $b_i$; we either leave it behind (using the result of previous solutions) or take it (using previous solutions in addition to the current benefit).\n\nFinally, any $w_i \\gt w$ cannot be used at all, so we rely on the results of subproblems.\n\nThe recurrence describing this algorithm is\n\\[\nv(i, w) = \\begin{cases}\n    0, & i = 0 \\\\\n    v(i-1, w), & w_i \\gt w \\\\\n    \\max\\big(v(i-1, w), v(i-1, w-w_i) + b_i\\big), & \\text{else}\n\\end{cases}\n\\]\n\n(c). We can tabulate the results of $v$ as we go, starting from the base cases of $v(0,w) = 0$ and running up through the possible $i$ and $w$ pairs. Each computation of the next results relies only on previous results, which are accessible in $O(1)$ time. Thus we compute the full table at a space and time cost $O(nW)$. With additional bookkeeping, we could maintain pointers to the items used in the optimal solution and reconstruct post facto.\n\n(d). The new decision problem partitions the set of items $I$ into $m \\le n$ types $T_k, k = \\{1 \\dots m\\}$ (note here that I am considering a combination of items $i,i'$—both having the same type—with value $(f(b_i,b_{i'}), w_i + w_{i'}, t_i)$ a separate item of the same type as $i$ and $i'$, extending the input beyond the original number of items). It then adds the new restriction that at most one item of each type $t \\in T$ can be present in the final solution.\n\nIn other words, items now have the form $(b_i, w_i, t_i)$.\n\nThis is the multiple-choice knapsack problem. [1] presents a DP approach to solving it on p. 16; the central idea is to eliminate items from the problem space that are \"dominated\" by other items in the type (the concept is that some items in a type can be guaranteed not to be a part of the solution based on other items in the type). They then build the solution by considering partial problems.\n\nThey further show an unchanged time complexity of $O(nW)$.\n\nThe change to the algorithm is that $v$ is parameterized by a maximum weight $w \\le W$ and the $l$th set of types ($l \\le m$) to consider; from the paper cited above, these problems $v(l,w)$ are defined by $\\max_{j \\in T_l}\\big(b_j + v(l-1,w-w_j)\\big)$. This represents the choice, for each item in $T_l$, of taking that item in addition to the best combination possible for the other types less the weight of the new item.\n\n[1]: \"Dudziniski, K., & Walukiewicz, S. (1987). Exact methods for the knapsack problem and its generalization. European Journal of Operational Research, 28, 3–21\" [https://www.sciencedirect.com/science/article/pii/0377221787901652]"
    }
  ]
}